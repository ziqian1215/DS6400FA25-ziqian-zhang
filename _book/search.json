[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ML1 Portoflio",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html",
    "href": "01-performance-measures.html",
    "title": "2  Measures of model performance",
    "section": "",
    "text": "2.1 Random Forest\nLet the dataset be\n\\[\nD=\\{(x_i,y_i)\\}_{i=1}^N,\\quad x_i\\in\\mathbb{R}^p,\\ y_i\\in\\{0,1\\}.\n\\]\nA Random Forest is an ensemble of \\(B\\) classification trees \\(\\{T_b\\}_{b=1}^B\\). Each tree is trained using:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "01-performance-measures.html#random-forest",
    "href": "01-performance-measures.html#random-forest",
    "title": "2  Measures of model performance",
    "section": "",
    "text": "Note. Random Forest can be applied to both classification and regression tasks.\nIn this chapter, we focus only on the classification setting, where the target variable \\(y_i \\in \\{0,1\\}\\) and each tree outputs class probabilities. The formulas and evaluation metrics described below are all for classification.\n\n\n\n\n\n2.1.1 Bootstrap sampling\nDraw a bootstrap sample \\(D_b^*\\) from \\(D\\) by sampling \\(N\\) observations with replacement.\n\\[\nD_b^* = \\{(x_{i_1},y_{i_1}),\\dots,(x_{i_N},y_{i_N})\\},\\quad i_j \\sim \\text{Unif}\\{1,\\dots,N\\}.\n\\]\n\n\n2.1.2 Random feature selection\nAt each internal node, randomly select \\(m_{\\text{try}}\\) features from the full set \\(\\{1,\\dots,p\\}\\).\nAmong the possible splits on these features, choose the one that maximizes the impurity decrease:\n\\[\n\\Delta \\mathcal{I}\n= \\mathcal{I}(\\text{parent})\n-\\sum_{c\\in\\{\\text{left},\\text{right}\\}}\n\\frac{n_c}{n_{\\text{parent}}}\\mathcal{I}(c).\n\\]\nA common impurity measure is the Gini impurity:\n\\[\n\\mathcal{I}_{\\text{Gini}}(\\text{node}) = 1 - \\sum_{k\\in\\{0,1\\}}\\hat{\\pi}_k^2,\n\\qquad\n\\hat{\\pi}_k = \\frac{1}{n_{\\text{node}}}\\sum_{i\\in\\text{node}}\\mathbb{1}(y_i=k).\n\\]\n\n\n2.1.3 Prediction\nEach tree \\(T_b\\) produces a probability estimate for the positive class:\n\\[\nT_b(x) = \\hat{p}_b(y=1\\mid x).\n\\]\nThe Random Forest averages these:\n\\[\n\\hat{p}(x) = \\frac{1}{B}\\sum_{b=1}^B T_b(x),\n\\qquad\n\\hat{y}(x) = \\mathbb{1}\\{\\hat{p}(x) \\ge 0.5\\}.\n\\]\nThis reduces variance and improves generalization.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#ten-fold-cross-validation",
    "href": "01-performance-measures.html#ten-fold-cross-validation",
    "title": "2  Measures of model performance",
    "section": "2.2 Ten-Fold Cross-Validation",
    "text": "2.2 Ten-Fold Cross-Validation\nWe split \\(D\\) into 10 disjoint folds of (approximately) equal size:\n\\[\nD = \\bigcup_{k=1}^{10} D_k,\\qquad D_i\\cap D_j = \\varnothing \\ (i\\neq j).\n\\]\nFor each fold \\(k\\):\n\nTraining set: \\(D^{(-k)} = D \\setminus D_k\\)\n\nTest set: \\(D_k\\)\n\nTrain the Random Forest on \\(D^{(-k)}\\) to obtain a fitted model \\(f_k(\\cdot)\\).\nUse it to produce predictions on all samples in \\(D_k\\):\n\\[\n\\{(\\hat{p}_k(x_i),\\hat{y}_k(x_i),y_i)\\}_{(x_i,y_i)\\in D_k}.\n\\]\nLet \\(M(\\cdot)\\) be a performance metric (Accuracy, F1, etc).\nDefine the fold-wise performance as\n\\[\nM_k = M\\big(\\{(\\hat{y}_k(x_i),y_i)\\}_{(x_i,y_i)\\in D_k}\\big).\n\\]\nThe cross-validated estimate is\n\\[\n\\overline{M} = \\frac{1}{10}\\sum_{k=1}^{10} M_k.\n\\]\n\n2.2.1 Standard error of the 10-fold CV mean (derivation)\nLet \\(M_1,\\dots,M_n\\) be the performance values (e.g., accuracy, F1, AUC, or MSE) computed on each of the \\(n\\) CV folds. For 10-fold CV, \\(n=10\\).\nStep 1 (fold mean).\nDefine the mean across folds \\[\n\\overline{M} \\;=\\; \\frac{1}{n}\\sum_{k=1}^n M_k \\, .\n\\]\nStep 2 (sample variance across folds).\nUse the unbiased sample variance with Bessel’s correction \\[\ns^2 \\;=\\; \\frac{1}{n-1}\\sum_{k=1}^n \\big(M_k-\\overline{M}\\big)^2 \\, .\n\\]\nStep 3 (standard error of the mean).\nThe standard error of the mean is the standard deviation of \\(\\overline{M}\\).\nWe estimate it by plugging in the sample standard deviation \\(s\\): \\[\n\\widehat{\\mathrm{SE}}(\\overline{M}) \\;=\\; \\frac{s}{\\sqrt{n}}\n\\;=\\; \\sqrt{\\frac{s^2}{n}} \\, .\n\\]\nStep 4 (combine Steps 2 and 3).\nSubstitute \\(s^2\\) from Step 2: \\[\n\\widehat{\\mathrm{SE}}(\\overline{M})\n\\;=\\;\n\\sqrt{ \\frac{1}{n}\\cdot \\frac{1}{n-1} \\sum_{k=1}^n \\big(M_k-\\overline{M}\\big)^2 }\n\\;=\\;\n\\sqrt{ \\frac{1}{n(n-1)} \\sum_{k=1}^n \\big(M_k-\\overline{M}\\big)^2 } \\, .\n\\]\nFor 10-fold CV (\\(n=10\\)), \\[\n\\widehat{\\mathrm{SE}}(\\overline{M})\n\\;=\\;\n\\sqrt{ \\frac{1}{10(10-1)} \\sum_{k=1}^{10} \\big(M_k-\\overline{M}\\big)^2 } \\, .\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#performance-metrics",
    "href": "01-performance-measures.html#performance-metrics",
    "title": "2  Measures of model performance",
    "section": "2.3 Performance Metrics",
    "text": "2.3 Performance Metrics\nOn a given test set, define confusion matrix counts:\n\\[\nTP=\\sum \\mathbb{1}\\{y_i=1,\\hat{y}_i=1\\},\\quad\nFP=\\sum \\mathbb{1}\\{y_i=0,\\hat{y}_i=1\\},\\quad\nTN=\\sum \\mathbb{1}\\{y_i=0,\\hat{y}_i=0\\},\\quad\nFN=\\sum \\mathbb{1}\\{y_i=1,\\hat{y}_i=0\\}.\n\\]\nThen:\n\\[\n\\mathrm{Accuracy}=\\frac{TP+TN}{TP+TN+FP+FN},\n\\qquad\n\\mathrm{Precision}=\\frac{TP}{TP+FP},\n\\qquad\n\\mathrm{Recall}=\\frac{TP}{TP+FN},\n\\]\n\\[\n\\mathrm{F1}=2\\frac{\\mathrm{Precision}\\cdot\\mathrm{Recall}}{\\mathrm{Precision}+\\mathrm{Recall}}.\n\\]\nAUC is the area under the ROC curve:\n\\[\n\\mathrm{AUC} = \\Pr(S^+ &gt; S^-)\n\\]\nwhere \\(S^+\\) and \\(S^-\\) are the scores from randomly drawn positive and negative examples.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#combining-rf-and-cv",
    "href": "01-performance-measures.html#combining-rf-and-cv",
    "title": "2  Measures of model performance",
    "section": "2.4 Combining RF and CV",
    "text": "2.4 Combining RF and CV\nFor each fold \\(k\\), compute the metrics on the test set \\(D_k\\).\nFor example, cross-validated accuracy is\n\\[\n\\overline{\\mathrm{Acc}} = \\frac{1}{10}\\sum_{k=1}^{10}\n\\frac{TP_k+TN_k}{TP_k+TN_k+FP_k+FN_k}.\n\\]\nDo the same for Precision, Recall, F1, and AUC.\nThese \\(\\overline{M}\\) values represent the estimated generalization performance of the Random Forest model.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "02-partial-effect-plots.html",
    "href": "02-partial-effect-plots.html",
    "title": "3  Model Visualization",
    "section": "",
    "text": "3.1 Data Generation\nWe generate data from the model:\n\\[\nE[Y \\mid X] = \\sqrt{5}\\,\\sigma(X_1 + X_3) + \\sqrt{5}\\,\\sigma(X_2)\\,X_3, \\quad\nV[Y \\mid X]=1,\n\\]\nwhere \\(X_1,X_2 \\sim \\mathcal N(0,1)\\), \\(X_3 \\sim \\text{Bernoulli}(0.4)\\), and \\(\\sigma(x)=1/(1+e^{-x})\\).\nlibrary(tidyverse)\n\nset.seed(42)\nn  &lt;- 2000\nX1 &lt;- rnorm(n)\nX2 &lt;- rnorm(n)\nX3 &lt;- rbinom(n, 1, 0.4)\n\nsigmoid &lt;- function(x) 1 / (1 + exp(-x))\nmu &lt;- sqrt(5) * sigmoid(X1 + X3) + sqrt(5) * sigmoid(X2) * X3\nY  &lt;- mu + rnorm(n, 0, 1)\n\ndat &lt;- tibble(X1, X2, X3 = factor(X3), Y)\nhead(dat)\n\n# A tibble: 6 × 4\n      X1     X2 X3        Y\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n1  1.37   0.251 0      1.85\n2 -0.565 -0.278 0      1.78\n3  0.363 -1.72  0      1.63\n4  0.633 -2.01  0      1.32\n5  0.404 -1.29  0      1.01\n6 -0.106  0.366 1      2.79",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Visualization</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#simulation-study",
    "href": "01-performance-measures.html#simulation-study",
    "title": "2  Measures of model performance",
    "section": "2.5 Simulation study",
    "text": "2.5 Simulation study\nThe following part shows the simulation study comparing LOO vs 10-fold CV for LDA & Random Forest.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#data-generation-model",
    "href": "01-performance-measures.html#data-generation-model",
    "title": "2  Measures of model performance",
    "section": "2.6 Data generation model",
    "text": "2.6 Data generation model\nWe simulate i.i.d. data \\(\\{(\\mathbf{T}_i, Y_i)\\}_{i=1}^n\\) as:\n\\[\nY_i \\sim \\mathrm{Bin}(1, 0.5), \\qquad\n\\mathbf{T}_i \\mid Y_i = y_i \\;\\sim\\; N_2\\!\\left(\n\\begin{bmatrix}\ny_i - \\tfrac{1}{2} \\\\\n0\n\\end{bmatrix},\n\\, I_2\n\\right),\n\\]\nwhere \\(I_2\\) is the \\(2\\times2\\) identity and \\(N_2\\) denotes the bivariate normal. Equivalently, conditional on \\(Y_i\\), the two features are independent with unit variance;\nthe first feature’s mean shifts by \\(y_i-0.5\\), making it informative for \\(Y\\).\n\n2.6.1 R implementation of data generation\n\n# Data generation function\ngenerate_data &lt;- function(N, seed = NULL) {\n  if (!is.null(seed)) set.seed(seed)\n  y  &lt;- rbinom(N, size = 1, prob = 0.5)                 # Bernoulli(0.5)\n  x1 &lt;- rnorm(N, mean = y - 0.5, sd = 1)                # mean depends on y\n  x2 &lt;- rnorm(N, mean = 0,       sd = 1)                # mean 0, unit sd\n  data.frame(\n    x1 = x1,\n    x2 = x2,\n    y  = factor(y, levels = c(0,1))\n  )\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#methods-evaluated",
    "href": "01-performance-measures.html#methods-evaluated",
    "title": "2  Measures of model performance",
    "section": "2.7 Methods evaluated",
    "text": "2.7 Methods evaluated\nWe evaluate two classifiers:\n\nLinear Discriminant Analysis (LDA)\nRandom Forest (RF)\n\nEach model’s generalization error is estimated using two cross-validation approaches:\n\nLeave-one-out cross-validation (LOO-CV):\n\\[\n\\widehat{R}_{\\text{LOO}} = \\frac{1}{n} \\sum_{i=1}^n \\ell(y_i, \\widehat{f}^{(-i)}(x_i)),\n\\] where \\(\\widehat{f}^{(-i)}\\) is trained without observation \\(i\\).\n10-fold cross-validation:\n\\[\n\\widehat{R}_{10\\text{-fold}} =\n\\frac{1}{10}\\sum_{k=1}^{10}\\frac{1}{|\\mathcal{I}_k|}\\sum_{i\\in\\mathcal{I}_k} \\ell(y_i,\\widehat{f}^{(-k)}(x_i)),\n\\] where folds \\(\\mathcal{I}_1,\\dots,\\mathcal{I}_{10}\\) partition the sample.\n\nThe loss function \\(\\ell\\) is 0–1 loss (misclassification error).\nWe then compare each estimator to the true error (approximated using a very large independent test set) and summarize performance using:\n\nBias: mean difference between estimated CV error and true error.\n\nVariance: variability of CV estimates across Monte Carlo replications.\n\nMSE: mean squared error, decomposed as\n\\[\n\\text{MSE} = (\\text{Bias})^2 + \\text{Variance}.\n\\]\n\n\n2.7.1 Libraries\n\nsuppressPackageStartupMessages({\n  library(MASS)          # for LDA\n  library(randomForest)  # for Random Forest\n  library(dplyr)\n  library(tibble)\n  library(purrr)\n  library(ggplot2)\n})\n\n\n\n2.7.2 Stratified folds, model wrappers, and error computation\n\nmake_stratified_folds &lt;- function(y, K = 10, seed = 1) {\n  set.seed(seed)\n  y &lt;- factor(y, levels = c(\"0\",\"1\"))\n  folds &lt;- integer(length(y))\n  for (lvl in levels(y)) {\n    idx &lt;- which(y == lvl)\n    idx &lt;- sample(idx)\n    splits &lt;- cut(seq_along(idx), breaks = K, labels = FALSE)\n    folds[idx] &lt;- splits\n  }\n  folds\n}\n\npredict_model &lt;- function(model_type, train_df, test_df, y_col = \"y\",\n                          rf_ntree = 500, rf_mtry = NULL) {\n  if (!is.factor(train_df[[y_col]])) train_df[[y_col]] &lt;- factor(train_df[[y_col]], levels = c(\"0\",\"1\"))\n  if (!is.factor(test_df[[y_col]]))  test_df[[y_col]]  &lt;- factor(test_df[[y_col]],  levels = c(\"0\",\"1\"))\n\n  if (model_type == \"lda\") {\n    fit &lt;- MASS::lda(as.formula(paste(y_col, \"~ .\")), data = train_df)\n    post &lt;- predict(fit, newdata = test_df)\n    pred &lt;- factor(ifelse(post$posterior[, \"1\"] &gt;= 0.5, \"1\", \"0\"), levels = c(\"0\",\"1\"))\n  } else if (model_type == \"rf\") {\n    if (is.null(rf_mtry)) rf_mtry &lt;- floor(sqrt(ncol(train_df) - 1))\n    fit &lt;- randomForest::randomForest(as.formula(paste(y_col, \"~ .\")),\n                                      data = train_df, ntree = rf_ntree, mtry = rf_mtry)\n    pred &lt;- predict(fit, newdata = test_df, type = \"response\")\n  } else stop(\"Unknown model_type\")\n\n  pred\n}\n\ncompute_error &lt;- function(y_true, pred) {\n  mean(pred != y_true)\n}\n\n\n\n2.7.3 Cross-validation evaluators\n\nevaluate_loo &lt;- function(df, model_type, rf_ntree = 500, rf_mtry = NULL) {\n  n &lt;- nrow(df)\n  errs &lt;- numeric(n)\n  for (i in seq_len(n)) {\n    test_idx  &lt;- i\n    train_idx &lt;- setdiff(seq_len(n), i)\n    train_df  &lt;- df[train_idx, , drop = FALSE]\n    test_df   &lt;- df[test_idx,  , drop = FALSE]\n    pred &lt;- predict_model(model_type, train_df, test_df, rf_ntree = rf_ntree, rf_mtry = rf_mtry)\n    errs[i] &lt;- compute_error(test_df$y, pred)\n  }\n  mean(errs)\n}\n\nevaluate_kfold &lt;- function(df, model_type, K = 10, seed = 1, rf_ntree = 500, rf_mtry = NULL) {\n  folds &lt;- make_stratified_folds(df$y, K = K, seed = seed)\n  errs &lt;- numeric(K)\n  for (k in seq_len(K)) {\n    test_idx  &lt;- which(folds == k)\n    train_idx &lt;- which(folds != k)\n    train_df  &lt;- df[train_idx, , drop = FALSE]\n    test_df   &lt;- df[test_idx,  , drop = FALSE]\n    pred &lt;- predict_model(model_type, train_df, test_df, rf_ntree = rf_ntree, rf_mtry = rf_mtry)\n    errs[k] &lt;- compute_error(test_df$y, pred)\n  }\n  mean(errs)\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#true-error-and-monte-carlo-evaluation",
    "href": "01-performance-measures.html#true-error-and-monte-carlo-evaluation",
    "title": "2  Measures of model performance",
    "section": "2.8 True error and Monte Carlo evaluation",
    "text": "2.8 True error and Monte Carlo evaluation\nTo evaluate the accuracy of cross-validation estimators, we need a benchmark:\nthe true generalization error of each model.\nFor a fitted classifier \\(f\\), the true error is defined as \\[\nR(f) = \\Pr\\{ f(\\mathbf{X}) \\neq Y \\},\n\\] where \\((\\mathbf{X}, Y)\\) is a new independent draw from the same distribution.\nSince this probability cannot be computed exactly, we approximate it using a very large independent test set (e.g., \\(N_\\text{test} = 50{,}000\\)).\nWe train the model on the entire observed dataset, then evaluate its misclassification rate on the test set.\n\n\n2.8.1 Function to estimate true error\n\nestimate_true_error &lt;- function(model_type, train_df, N_test = 50000,\n                                rf_ntree = 500, rf_mtry = NULL) {\n  # Generate large independent test set\n  test_df &lt;- generate_data(N_test)\n  pred &lt;- predict_model(model_type, train_df, test_df, rf_ntree = rf_ntree, rf_mtry = rf_mtry)\n  compute_error(test_df$y, pred)\n}\n\n\none_replication &lt;- function(N, seed = NULL) {\n  if (!is.null(seed)) set.seed(seed)\n  df &lt;- generate_data(N)\n\n  # LDA\n  lda_loo   &lt;- evaluate_loo(df, \"lda\")\n  lda_k10   &lt;- evaluate_kfold(df, \"lda\", K = 10, seed = 1)\n  lda_true  &lt;- estimate_true_error(\"lda\", df)\n\n  # RF\n  rf_loo    &lt;- evaluate_loo(df, \"rf\")\n  rf_k10    &lt;- evaluate_kfold(df, \"rf\", K = 10, seed = 1)\n  rf_true   &lt;- estimate_true_error(\"rf\", df)\n\n  tibble::tibble(\n    N        = N,\n    model    = c(\"LDA\",\"LDA\",\"RF\",\"RF\"),\n    method   = c(\"LOO\",\"10-fold\",\"LOO\",\"10-fold\"),\n    est_err  = c(lda_loo, lda_k10, rf_loo, rf_k10),\n    true_err = c(lda_true, lda_true, rf_true, rf_true)\n  )\n}\n\n\nset.seed(20250925)\none_replication(40)\n\n# A tibble: 4 × 5\n      N model method  est_err true_err\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1    40 LDA   LOO       0.325    0.323\n2    40 LDA   10-fold   0.285    0.323\n3    40 RF    LOO       0.425    0.333\n4    40 RF    10-fold   0.38     0.333",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#simulation-setup",
    "href": "01-performance-measures.html#simulation-setup",
    "title": "2  Measures of model performance",
    "section": "2.9 Simulation Setup",
    "text": "2.9 Simulation Setup\nThe code below runs a Monte Carlo simulation across multiple sample sizes. It defines a set of sample sizes (Ns) and the number of replications (R=20) to run for each, sets a random seed for reproducibility, and initializes an empty list to store results. For each sample size (N) and replication (r), the function one_replication(N) is called to perform a single experiment, the output is tagged with the replication index, and then appended to the results list. In the end, results_list contains all simulated outcomes across every combination of sample size and replication, providing the data needed for further summarization and analysis.\n\nNs &lt;- c( 20, 30, 40, 50, 75, 100)\nR  &lt;- 20  # increase for tighter Monte Carlo precision\nset.seed(123)\nresults_list &lt;- list()\n\nfor (N in Ns) {\n  for (r in 1:R) {\n    res &lt;- one_replication(N)\n    res$rep &lt;- r\n    results_list &lt;- append(results_list, list(res))\n  }\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "01-performance-measures.html#summary",
    "href": "01-performance-measures.html#summary",
    "title": "2  Measures of model performance",
    "section": "2.10 Summary",
    "text": "2.10 Summary\n\nresults &lt;- dplyr::bind_rows(results_list)\nggplot(results, aes(x = factor(N), y = est_err, color = method)) +\n  geom_boxplot(outlier.alpha = 0.3, position = position_dodge(width = 0.8)) +\n  stat_summary(fun = mean, geom = \"line\", aes(group = method),\n               position = position_dodge(width = 0.8)) +\n  stat_summary(fun = mean, geom = \"point\", aes(group = method),\n               position = position_dodge(width = 0.8), size = 2) +\n  facet_wrap(~ model) +\n  labs(\n    title = \"Distribution of CV Estimates vs. True Error\",\n    x = \"Sample size N\",\n    y = \"Estimated error rate\",\n    color = \"CV Method\"\n  ) +\n  theme_minimal(base_size = 12)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measures of model performance</span>"
    ]
  },
  {
    "objectID": "02-partial-effect-plots.html#model-linear-regression-with-natural-splines",
    "href": "02-partial-effect-plots.html#model-linear-regression-with-natural-splines",
    "title": "3  Model Visualization",
    "section": "3.2 Model: Linear Regression with Natural Splines",
    "text": "3.2 Model: Linear Regression with Natural Splines\nWe model a flexible, nonlinear relationship by replacing raw predictors with natural cubic spline bases.\nLet \\(f_1(\\cdot)\\) and \\(f_2(\\cdot)\\) be smooth functions represented by spline bases. We fit\n\\[\nY \\;=\\; \\beta_0 \\;+\\; f_1(X_1)\\;+\\; f_2(X_2)\\\\;+\\; \\gamma\\,\\mathbb{1}(X_3)\\;+\\; \\varepsilon,\n\\quad \\varepsilon \\sim \\mathcal{N}(0,\\sigma^2).\n\\]\n\nns(X1, df=5) and ns(X2, df=5) are natural spline bases with 5 degrees of freedom.\n\nns(X3, df=3) effectively lets the model represent it smoothly if treated as numeric, but it’s basically equivalent to a categorical main effect.\n\n\nlibrary(splines)\nlm_spline &lt;- lm(\n  Y ~ ns(X1, df = 5) + ns(X2, df = 5) + ns(as.numeric(X3), df = 3),\n  data = dat\n)\n\nWarning in ns(as.numeric(X3), df = 3): shoving 'interior' knots matching\nboundary knots to inside",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Visualization</span>"
    ]
  },
  {
    "objectID": "02-partial-effect-plots.html#partial-effect-plots",
    "href": "02-partial-effect-plots.html#partial-effect-plots",
    "title": "3  Model Visualization",
    "section": "3.3 Partial Effect Plots",
    "text": "3.3 Partial Effect Plots\nWhat is a partial effect plot?\nFor an lm with splines, a partial effect (component-plus-residual) plot shows how a predictor contributes to the fitted values after adjusting for all other terms. We compute the term contribution for a variable (from predict(mod, type = \"terms\")), add the model residuals to form partial residuals, and plot those against the raw predictor. A smooth (LOESS) curve with a confidence band visualizes the nonlinear effect learned by the spline.\n\n3.3.1 Helper functions\nThe two helpers below produce ggplot figures: - simple_peplot() — single numeric predictor - simple_peplot_by() — numeric predictor split into separate curves by a factor (e.g., X3)\n\nsimple_peplot &lt;- function(mod, var, data, span = 0.8) {\n  tt &lt;- predict(mod, type = \"terms\")\n  cn &lt;- colnames(tt)\n  pick &lt;- grep(paste0(\"\\\\b\", var, \"\\\\b\"), cn)\n  if (length(pick) == 0L) stop(\"No model terms matched '\", var, \"'.\")\n  term_contrib &lt;- rowSums(tt[, pick, drop = FALSE])\n  pr &lt;- term_contrib + residuals(mod)\n  x  &lt;- data[[var]]\n\n  ggplot(tibble(x = x, pr = pr), aes(x, pr)) +\n    geom_point(alpha = 0.35, size = 1, color = \"steelblue\") +\n    geom_smooth(method = \"loess\", span = span, se = TRUE, linewidth = 1.1) +\n    labs(x = var, y = \"Partial residual\", title = paste(\"Partial effect of\", var)) +\n    theme_bw(base_size = 12)\n}\n\nsimple_peplot_by &lt;- function(mod, var, by, data, span = 0.8) {\n  tt &lt;- predict(mod, type = \"terms\")\n  pick &lt;- grep(paste0(\"\\\\b\", var, \"\\\\b\"), colnames(tt))\n  stopifnot(length(pick) &gt; 0)\n  term_contrib &lt;- rowSums(tt[, pick, drop = FALSE])\n  pr &lt;- term_contrib + residuals(mod)\n\n  df &lt;- tibble(x = data[[var]], pr = pr, grp = data[[by]])\n\n  ggplot(df, aes(x, pr, color = grp)) +\n    geom_point(alpha = 0.3, size = 1) +\n    geom_smooth(method = \"loess\", span = span, se = TRUE, linewidth = 1.1) +\n    labs(x = var, y = \"Partial residual\",\n         title = paste(\"Partial effect of\", var, \"by\", by), color = by) +\n    theme_bw(base_size = 12)\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Visualization</span>"
    ]
  },
  {
    "objectID": "02-partial-effect-plots.html#final-plots",
    "href": "02-partial-effect-plots.html#final-plots",
    "title": "3  Model Visualization",
    "section": "3.4 Final Plots",
    "text": "3.4 Final Plots\nNow we put everything together: plotting the partial effects of our spline-based linear regression.\n\nsimple_peplot(lm_spline, \"X1\", data = dat)\n\n\n\n\n\n\n\nsimple_peplot(lm_spline, \"X2\", data = dat)\n\n\n\n\n\n\n\nsimple_peplot_by(lm_spline, var = \"X1\", by = \"X3\", data = dat)\n\n\n\n\n\n\n\nsimple_peplot_by(lm_spline, var = \"X2\", by = \"X3\", data = dat)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Visualization</span>"
    ]
  },
  {
    "objectID": "02-partial-effect-plots.html#random-forest-with-partial-dependence-plots",
    "href": "02-partial-effect-plots.html#random-forest-with-partial-dependence-plots",
    "title": "3  Model Visualization",
    "section": "3.5 Random Forest with Partial Dependence Plots",
    "text": "3.5 Random Forest with Partial Dependence Plots\n\nlibrary(pdp)            \n\n\nAttaching package: 'pdp'\n\n\nThe following object is masked from 'package:purrr':\n\n    partial\n\nlibrary(patchwork) \nlibrary(randomForest) \n\nrandomForest 4.7-1.2\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nrf &lt;- randomForest(Y ~ X1 + X2 + X3, data = dat, ntree = 500, mtry = 2, importance = TRUE)\n\n\npstyle &lt;- function(p, title) p + labs(title = title, x = NULL, y = \"Partial dependence\") +\n  theme_bw(base_size = 12)\n\np_rf_x1 &lt;- partial(rf, pred.var = \"X1\", grid.resolution = 60, train = dat)     |&gt; autoplot() |&gt; pstyle(\"RF: effect of X1\")\np_rf_x2 &lt;- partial(rf, pred.var = \"X2\", grid.resolution = 60, train = dat)     |&gt; autoplot() |&gt; pstyle(\"RF: effect of X2\")\np_rf_x3 &lt;- partial(rf, pred.var = \"X3\", grid.resolution = 2,  train = dat)     |&gt; autoplot() |&gt; pstyle(\"RF: effect of X3\")\n\n# Spline-Linear PDPs\np_lm_x1 &lt;- partial(lm_spline, pred.var = \"X1\", grid.resolution = 60, train = dat) |&gt; autoplot() |&gt; pstyle(\"Spline-LM: effect of X1\")\np_lm_x2 &lt;- partial(lm_spline, pred.var = \"X2\", grid.resolution = 60, train = dat) |&gt; autoplot() |&gt; pstyle(\"Spline-LM: effect of X2\")\np_lm_x3 &lt;- partial(lm_spline, pred.var = \"X3\", grid.resolution = 2,  train = dat) |&gt; autoplot() |&gt; pstyle(\"Spline-LM: effect of X3\")\n\n(p_rf_x1 | p_rf_x2 | p_rf_x3) /\n(p_lm_x1 | p_lm_x2 | p_lm_x3)\n\n\n\n\n\n\n\n\n\npstyle &lt;- function(p, title) p +\n  labs(title = title, x = NULL, y = \"Partial dependence\") +\n  theme_bw(base_size = 12)\n\np_rf_x1_x3 &lt;- partial(rf, pred.var = c(\"X1\", \"X3\"), grid.resolution = 60, train = dat) |&gt;\n  autoplot(rug = FALSE, contour = FALSE) |&gt; pstyle(\"RF: effect of X1 by X3\")\n\np_rf_x2_x3 &lt;- partial(rf, pred.var = c(\"X2\", \"X3\"), grid.resolution = 60, train = dat) |&gt;\n  autoplot(rug = FALSE, contour = FALSE) |&gt; pstyle(\"RF: effect of X2 by X3\")\n\np_rf_x1_x3 / p_rf_x2_x3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Visualization</span>"
    ]
  },
  {
    "objectID": "02-partial-effect-plots.html#individual-conditional-expectation-ice-plots",
    "href": "02-partial-effect-plots.html#individual-conditional-expectation-ice-plots",
    "title": "3  Model Visualization",
    "section": "3.6 Individual Conditional Expectation (ICE) plots",
    "text": "3.6 Individual Conditional Expectation (ICE) plots\nICE shows one curve per observation, revealing heterogeneity that PDP/PE can hide.\n\n# ---- helpers styled like pstyle() \npstyle_fx &lt;- function(p, title, xlab, ylab) {\n  p + labs(title = title, x = xlab, y = ylab) + theme_bw(base_size = 12)\n}\n\n# ---- ICE\nplot_ice &lt;- function(model, data, var, grid.size = 60, title = NULL) {\n  grid_vals &lt;- seq(min(data[[var]]), max(data[[var]]), length.out = grid.size)\n\n  ice_data &lt;- purrr::map_dfr(seq_len(nrow(data)), function(i) {\n    new_dat &lt;- data[rep(i, grid.size), ]\n    new_dat[[var]] &lt;- grid_vals\n    tibble(\n      ID   = i,\n      x    = grid_vals,\n      yhat = as.numeric(predict(model, newdata = new_dat))\n    )\n  })\n\n  pdp_data &lt;- ice_data |&gt;\n    dplyr::group_by(x) |&gt;\n    dplyr::summarise(mean_y = mean(yhat), .groups = \"drop\")\n\n  g &lt;- ggplot(ice_data, aes(x = x, y = yhat, group = ID)) +\n    geom_line(alpha = 0.18, linewidth = 0.4, color = \"steelblue\") +\n    geom_line(data = pdp_data, aes(x = x, y = mean_y),\n              inherit.aes = FALSE, color = \"red\", linewidth = 1.1)\n\n  pstyle_fx(g, title %||% paste0(\"ICE: \", var), xlab = var, ylab = \"Predicted Y\")\n}\n\n# ---- ICE by a factor (e.g., X3) ----\nplot_ice_by &lt;- function(model, data, var, by, grid.size = 60, title = NULL) {\n  grid_vals &lt;- seq(min(data[[var]]), max(data[[var]]), length.out = grid.size)\n\n  ice_data &lt;- purrr::map_dfr(seq_len(nrow(data)), function(i) {\n    new_dat &lt;- data[rep(i, grid.size), ]\n    new_dat[[var]] &lt;- grid_vals\n    tibble(\n      ID   = i,\n      grp  = new_dat[[by]][1],\n      x    = grid_vals,\n      yhat = as.numeric(predict(model, newdata = new_dat))\n    )\n  })\n\n  pdp_data &lt;- ice_data |&gt;\n    dplyr::group_by(grp, x) |&gt;\n    dplyr::summarise(mean_y = mean(yhat), .groups = \"drop\")\n\n  g &lt;- ggplot(ice_data, aes(x = x, y = yhat, group = interaction(ID, grp), color = grp)) +\n    geom_line(alpha = 0.18, linewidth = 0.35) +\n    geom_line(data = pdp_data, aes(x = x, y = mean_y, color = grp),\n              inherit.aes = FALSE, linewidth = 1.05)\n\n  pstyle_fx(g, title %||% paste0(\"ICE: \", var, \" by \", by), xlab = var, ylab = \"Predicted Y\")\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Visualization</span>"
    ]
  },
  {
    "objectID": "02-partial-effect-plots.html#accumulated-local-effects-ale-plots",
    "href": "02-partial-effect-plots.html#accumulated-local-effects-ale-plots",
    "title": "3  Model Visualization",
    "section": "3.7 Accumulated Local Effects (ALE) plots",
    "text": "3.7 Accumulated Local Effects (ALE) plots\nALE curves summarize local effects and are often more reliable than PDP when features are correlated.\n\n# ---- ALE (no extra packages) ----\nplot_ale &lt;- function(model, data, var, grid.size = 40, title = NULL) {\n  qs &lt;- stats::quantile(data[[var]], probs = seq(0, 1, length.out = grid.size), names = FALSE)\n  mids &lt;- (qs[-1] + qs[-length(qs)]) / 2\n\n  delta &lt;- numeric(length(qs) - 1)\n  for (k in seq_len(length(delta))) {\n    low  &lt;- qs[k]; high &lt;- qs[k + 1]\n    idx &lt;- which(data[[var]] &gt;= low & data[[var]] &lt; high)\n    if (length(idx)) {\n      dat_low  &lt;- data[idx, ];  dat_low[[var]]  &lt;- low\n      dat_high &lt;- data[idx, ]; dat_high[[var]] &lt;- high\n      delta[k] &lt;- mean(predict(model, dat_high) - predict(model, dat_low))\n    } else {\n      delta[k] &lt;- 0\n    }\n  }\n\n  ale &lt;- cumsum(delta)\n  ale &lt;- ale - mean(ale)\n\n  g &lt;- ggplot(tibble(x = mids, y = ale), aes(x, y)) +\n    geom_line(linewidth = 1.1)\n\n  pstyle_fx(g, title %||% paste0(\"ALE: \", var), xlab = var, ylab = \"Accumulated local effect\")\n}\n\n\n# ICE / ALE for the spline model\nice_x1 &lt;- plot_ice(lm_spline, dat, \"X1\", grid.size = 60, title = \"ICE: X1 (Spline-LM)\")\nice_x2 &lt;- plot_ice(lm_spline, dat, \"X2\", grid.size = 60, title = \"ICE: X2 (Spline-LM)\")\n\nale_x1 &lt;- plot_ale(lm_spline, dat, \"X1\", grid.size = 40, title = \"ALE: X1 (Spline-LM)\")\nale_x2 &lt;- plot_ale(lm_spline, dat, \"X2\", grid.size = 40, title = \"ALE: X2 (Spline-LM)\")\n\nice_x2_byx3 &lt;- plot_ice_by(lm_spline, dat, var = \"X2\", by = \"X3\", grid.size = 60,\n                           title = \"ICE: X2 by X3 (Spline-LM)\")\n\n# Arrange like your PDP grid\n(ice_x1 | ice_x2) /\n(ale_x1 | ale_x2)\n\n\n\n\n\n\n\n# Show the grouped ICE as well\nice_x2_byx3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Visualization</span>"
    ]
  },
  {
    "objectID": "03-4-models.html",
    "href": "03-4-models.html",
    "title": "4  4 Models",
    "section": "",
    "text": "4.1 Generalized Linear Model (GLM)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#generalized-linear-model-glm",
    "href": "03-4-models.html#generalized-linear-model-glm",
    "title": "4  4 Models",
    "section": "",
    "text": "4.1.1 Motivating Ideas\nThe Generalized Linear Model (GLM) represents a major unifying step in the history of statistics.\nBefore 1972, researchers used a collection of specialized methods for different kinds of data:\n\nContinuous data: Multiple linear regression (Normal distribution, identity link)\n\nGroup mean comparisons: ANOVA (Normal distribution, identity link)\n\nBinary data: Logistic or probit regression (Binomial distribution, logit/probit link)\n\nCount data: Poisson regression (Poisson distribution, log link)\n\nEach model had its own estimation rules and assumptions.\nNelder and Wedderburn (1972) proposed GLMs as a single framework that could describe all of these models through three shared components:\n\nA random component:\nThe response variable \\(Y_i\\) follows a distribution from the exponential family (e.g., Normal, Binomial, Poisson, Gamma).\nA systematic component:\nPredictors enter linearly through\n\\[\n\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\]\nA link function:\nConnects the expected value \\(\\mu_i = E[Y_i]\\) to the linear predictor:\n\\[\ng(\\mu_i) = \\eta_i.\n\\]\n\nWith this formulation, the same estimation algorithm — Iteratively Reweighted Least Squares (IRLS) — can be used across models.\nGLMs thus generalized linear regression to non-normal data while keeping the interpretability of regression coefficients.\n\n\n4.1.2 Chronology of Key Ideas\nAdapted from Lindsey’s summary of McCullagh & Nelder (who themselves drew from Stiegler), the historical path toward GLMs developed gradually:\n\n\n\n\n\n\n\n\n\nPeriod\nDevelopment\nDistribution & Link\nKey Contributors\n\n\n\n\nEarly 19th century\nMultiple linear regression — foundation of least squares.\nNormal, identity\nLegendre, Gauss\n\n\n1920s–1935\nANOVA formalized — partitioning of variance.\nNormal, identity\nFisher\n\n\n1922\nLikelihood function introduced — general approach to inference.\nAny\nFisher\n\n\n1922\nDilution assays for dose–response data.\nBinomial, complementary log–log\nFisher\n\n\n1934\nExponential family identified — distributions with sufficient statistics.\n—\nFisher\n\n\n1935\nProbit analysis for quantal response data.\nBinomial, probit\nBliss\n\n\n1944–1952\nLogit model for proportions.\nBinomial, logit\nBerkson; Dyke & Patterson\n\n\n1960\nItem response theory (Rasch model).\nBernoulli, logit\nRasch\n\n\n1963\nLog-linear models for count data.\nPoisson, log\nBirch\n\n\n1965–1967\nRegression models for survival data.\nExponential, log or reciprocal\nFeigl & Zelen; Zippin & Armitage; Glasser\n\n\n1966\nInverse polynomials extended regression to Gamma data.\nGamma, reciprocal\nNelder\n\n\n1972\nGeneralized Linear Models unified all the above under one theory and algorithm.\nExponential family, general link\nNelder & Wedderburn",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#conceptual-unification",
    "href": "03-4-models.html#conceptual-unification",
    "title": "4  4 Models",
    "section": "4.2 Conceptual Unification",
    "text": "4.2 Conceptual Unification\nBy the early 1970s, it became clear that many well-known models were specific cases of a broader principle.\nNelder and Wedderburn (1972) formally expressed this as:\n\\[\ng(\\mu_i) = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}, \\quad\nY_i \\sim \\text{Exponential Family}(\\mu_i, \\phi)\n\\]\nTheir key insight:\n\nAll these models (linear, logistic, Poisson, Gamma, etc.) share the same likelihood structure.\n\nThey can all be estimated through the same maximum-likelihood algorithm.\n\nDiagnostics, residuals, and hypothesis tests could be made consistent across model types.\n\nIn short, GLMs provided the long-sought unification of statistical modeling, bringing together 150 years of development—from Gauss’s least squares and Fisher’s likelihood theory to modern regression frameworks.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#references",
    "href": "03-4-models.html#references",
    "title": "4  4 Models",
    "section": "4.3 References",
    "text": "4.3 References\n\nLegendre, A. M. (1805). Nouvelles méthodes pour la détermination des orbites des comètes.\n\nGauss, C. F. (1809). Theoria motus corporum coelestium in sectionibus conicis solem ambientium.\n\nFisher, R. A. (1922). On the mathematical foundations of theoretical statistics. Philosophical Transactions of the Royal Society A.\n\nBliss, C. I. (1935). The method of probits. Science, 79(2037), 38–39.\n\nBerkson, J. (1944). Application of the logistic function to bio-assay. JASA, 39(227), 357–365.\n\nRasch, G. (1960). Probabilistic models for some intelligence and attainment tests.\n\nBirch, M. W. (1963). Maximum likelihood in three-way contingency tables. JASA, 58, 1071–1081.\n\nFeigl, P., & Zelen, M. (1965). Estimation of exponential survival probabilities with concomitant information. Biometrics, 21, 826–838.\n\nNelder, J. A., & Wedderburn, R. W. M. (1972). Generalized Linear Models. JRSS A, 135(3), 370–384.\n\nMcCullagh, P., & Nelder, J. A. (1989). Generalized Linear Models (2nd ed.). Chapman & Hall.\n\nLindsey, J. K. (1997). Applying Generalized Linear Models. Springer.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#expressing-the-glm-mathematically",
    "href": "03-4-models.html#expressing-the-glm-mathematically",
    "title": "4  4 Models",
    "section": "4.4 Expressing the GLM Mathematically",
    "text": "4.4 Expressing the GLM Mathematically\nA single-parameter exponential family can be expressed as:\n\\[\nf_X(x \\mid \\theta)\n= h(x)\\,\\exp\\!\\left[\\eta(\\theta)\\,T(x) - A(\\theta)\\right],\n\\]\nor equivalently,\n\\[\n\\log f_X(x \\mid \\theta)\n= \\eta(\\theta)\\,T(x) - A(\\theta) + B(x).\n\\]\n\n4.4.1 Components\n\n\n\n\n\n\n\n\nSymbol\nRole\nGLM Interpretation\n\n\n\n\n\\[T(x)\\]\nSufficient statistic\nResponse variable \\[Y_i\\]\n\n\n\\[h(x)\\] or \\[B(x)\\]\nBase measure\nConstant term \\[c(y_i, \\phi)\\]\n\n\n\\[\\eta(\\theta)\\]\nNatural (canonical) parameter\nLinear predictor \\[\\eta_i = X_i^\\top \\beta\\] under canonical link\n\n\n\\[A(\\theta)\\]\nCumulant (log-partition) function\nDetermines mean and variance\n\n\n\\[\\theta\\]\nModel parameter\nCanonical parameter of the distribution\n\n\n\nFor any exponential-family member:\n\\[\n\\mathbb{E}[T(X)] = A'(\\theta),\n\\]\n\\[\n\\mathrm{Var}[T(X)] = A''(\\theta).\n\\]\nThus, for GLMs:\n\\[\n\\mu_i = \\mathbb{E}[Y_i] = A'(\\theta_i),\n\\]\n\\[\n\\mathrm{Var}(Y_i) = a(\\phi) A''(\\theta_i),\n\\]\nand the link function connects the mean to the predictors:\n\\[\ng(\\mu_i) = \\eta_i = X_i^\\top \\beta.\n\\]\nIf the link is canonical, then:\n\\[\ng(\\mu_i) = \\theta_i.\n\\]\n\n\n\n4.4.2 Binomial Distribution (Logistic GLM)\n\\[\nY_i \\sim \\text{Binomial}(n_i, p_i)\n\\]\nFor simplicity, we often take \\[n_i = 1\\] so that:\n\\[\nY_i \\sim \\text{Binomial}(1, p_i).\n\\]\nThe probability mass function is:\n\\[\nf_Y(y_i \\mid p_i) = \\binom{n_i}{y_i} p_i^{y_i} (1 - p_i)^{n_i - y_i}.\n\\]\nThis can be written in exponential-family form:\n\\[\nf_Y(y_i \\mid \\theta_i)\n= h(y_i)\\,\\exp\\!\\left[y_i \\theta_i - A(\\theta_i)\\right],\n\\]\nwhere:\n\\[\n\\theta_i = \\log\\!\\frac{p_i}{1 - p_i},\n\\]\n\\[\nA(\\theta_i) = n_i \\log(1 + e^{\\theta_i}),\n\\]\n\\[\nh(y_i) = \\binom{n_i}{y_i}.\n\\]\nThen the mean and variance follow from derivatives of \\[A(\\theta_i)\\]:\n\\[\n\\mu_i = A'(\\theta_i) = n_i \\frac{e^{\\theta_i}}{1 + e^{\\theta_i}} = n_i p_i,\n\\]\n\\[\n\\mathrm{Var}(Y_i) = A''(\\theta_i) = n_i p_i (1 - p_i).\n\\]\nThe canonical link function is the logit:\n\\[\ng(p_i) = \\log\\!\\frac{p_i}{1 - p_i} = \\eta_i = X_i^\\top \\beta,\n\\]\nand the inverse link (mean function) is:\n\\[\np_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}}.\n\\]\n\n\n\n4.4.3 Poisson Distribution (Log-linear GLM)\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i)\n\\]\nThe probability mass function is:\n\\[\nf_Y(y_i \\mid \\lambda_i) = \\frac{\\lambda_i^{y_i} e^{-\\lambda_i}}{y_i!}.\n\\]\nThis can be expressed in exponential-family form:\n\\[\nf_Y(y_i \\mid \\theta_i)\n= h(y_i)\\,\\exp\\!\\left[y_i \\theta_i - A(\\theta_i)\\right],\n\\]\nwhere:\n\\[\n\\theta_i = \\log \\lambda_i,\n\\]\n\\[\nA(\\theta_i) = e^{\\theta_i},\n\\]\n\\[\nh(y_i) = \\frac{1}{y_i!}.\n\\]\nFrom these we derive:\n\\[\n\\mu_i = A'(\\theta_i) = e^{\\theta_i} = \\lambda_i,\n\\]\n\\[\n\\mathrm{Var}(Y_i) = A''(\\theta_i) = e^{\\theta_i} = \\lambda_i.\n\\]\nThe canonical link is the log link:\n\\[\ng(\\mu_i) = \\log \\mu_i = \\eta_i = X_i^\\top \\beta,\n\\]\nand the inverse link is:\n\\[\n\\mu_i = e^{\\eta_i}.\n\\]\nIf we model rates with exposure \\[E_i\\]:\n\\[\n\\log \\lambda_i = \\log E_i + X_i^\\top \\beta,\n\\]\nor equivalently:\n\\[\n\\lambda_i = E_i\\,e^{X_i^\\top \\beta}.\n\\]\n\n\n\n4.4.4 Summary Table\n\n\n\n\n\n\n\n\n\n\n\nDistribution\nCanonical Parameter \\[\\theta\\]\nCumulant \\[A(\\theta)\\]\nMean \\[A'(\\theta)\\]\nVariance \\[A''(\\theta)\\]\nCanonical Link\n\n\n\n\n\\[Y_i \\sim \\text{Binomial}(1, p_i)\\]\n\\[\\log\\frac{p_i}{1-p_i}\\]\n\\[\\log(1 + e^{\\theta})\\]\n\\[p_i\\]\n\\[p_i(1 - p_i)\\]\nLogit\n\n\n\\[Y_i \\sim \\text{Poisson}(\\lambda_i)\\]\n\\[\\log \\lambda_i\\]\n\\[e^{\\theta}\\]\n\\[\\lambda_i\\]\n\\[\\lambda_i\\]\nLog\n\n\n\n\n\n\n4.4.5 What We Will Demonstrate in Code\n\nSimulate Data\n\nBinomial: \\[Y_i \\sim \\text{Binomial}(1, p_i)\\]\n\nPoisson: \\[Y_i \\sim \\text{Poisson}(\\lambda_i)\\]\n\nFit GLMs with Canonical Links\n\nLogistic GLM: \\[g(p_i) = \\log\\frac{p_i}{1-p_i}\\]\n\nPoisson GLM: \\[g(\\lambda_i) = \\log \\lambda_i\\]\n\nVerify Theoretical Relationships\n\nMean: \\[\\mu_i = A'(\\theta_i)\\]\n\nVariance: \\[\\mathrm{Var}(Y_i) = A''(\\theta_i)\\]\n\nCanonical link linearity: \\[g(\\mu_i) = X_i^\\top \\beta\\]\n\nVisualize Results\n\nPredicted vs observed \\[Y_i\\]\n\nInverse-link response curves \\[g^{-1}(\\eta_i)\\]\n\nDeviance and residual diagnostics",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#code",
    "href": "03-4-models.html#code",
    "title": "4  4 Models",
    "section": "4.5 Code",
    "text": "4.5 Code\n\nset.seed(1)\nn  &lt;- 500\nx1 &lt;- rnorm(n)\nx2 &lt;- rnorm(n)\neta &lt;- -0.5 + 1.1*x1 - 0.8*x2\np   &lt;- plogis(eta)\ny   &lt;- rbinom(n, size = 1, prob = p)\n\ndf &lt;- data.frame(y, x1, x2)\n\nm_logit &lt;- glm(y ~ x1 + x2, data = df, family = binomial())\nsummary(m_logit)\n\n\nCall:\nglm(formula = y ~ x1 + x2, family = binomial(), data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.3858     0.1078  -3.579 0.000344 ***\nx1            1.1572     0.1318   8.780  &lt; 2e-16 ***\nx2           -0.7521     0.1107  -6.794 1.09e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 685.93  on 499  degrees of freedom\nResidual deviance: 530.03  on 497  degrees of freedom\nAIC: 536.03\n\nNumber of Fisher Scoring iterations: 4\n\n# Effect curve for x1 (x2 fixed at 0), with 95% CI on response scale\nlibrary(ggplot2)\nxgrid &lt;- data.frame(x1 = seq(-3, 3, length.out = 200), x2 = 0)\npred  &lt;- predict(m_logit, newdata = xgrid, type = \"link\", se.fit = TRUE)\neta_hat &lt;- pred$fit\nse_eta  &lt;- pred$se.fit\np_hat   &lt;- plogis(eta_hat)\nlo      &lt;- plogis(eta_hat - 1.96*se_eta)\nhi      &lt;- plogis(eta_hat + 1.96*se_eta)\n\nggplot() +\n  geom_point(aes(x = x1, y = y), data = df, alpha = 0.25) +\n  geom_line(aes(x = xgrid$x1, y = p_hat), linewidth = 1) +\n  geom_ribbon(aes(x = xgrid$x1, ymin = lo, ymax = hi), alpha = 0.2) +\n  labs(title = \"Binomial GLM (logit): effect of x1 | x2=0\",\n       x = \"x1\", y = \"P(Y=1)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Quick residual check\nplot(fitted(m_logit), residuals(m_logit, type = \"deviance\"),\n     xlab = \"Fitted probability\", ylab = \"Deviance residual\",\n     main = \"Logistic GLM: residuals vs fitted\")\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n\n\n\nset.seed(2)\nn  &lt;- 500\nx1 &lt;- rnorm(n)\nx2 &lt;- rnorm(n)\nE  &lt;- runif(n, 0.5, 2.5)                # exposure\neta &lt;- 0.2 + 0.5*x1 + 0.6*x2 + log(E)   # include offset in DGP\nlambda &lt;- exp(eta)\ny  &lt;- rpois(n, lambda)\n\ndfp &lt;- data.frame(y, x1, x2, E)\n\nm_pois &lt;- glm(y ~ x1 + x2 + offset(log(E)), data = dfp, family = poisson())\nsummary(m_pois)\n\n\nCall:\nglm(formula = y ~ x1 + x2 + offset(log(E)), family = poisson(), \n    data = dfp)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.24655    0.03577   6.892  5.5e-12 ***\nx1           0.50714    0.02559  19.814  &lt; 2e-16 ***\nx2           0.59661    0.02793  21.359  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1337.16  on 499  degrees of freedom\nResidual deviance:  498.35  on 497  degrees of freedom\nAIC: 1634.3\n\nNumber of Fisher Scoring iterations: 5\n\n# Effect curve for x1 (x2 = 0, E = 1), with 95% CI on mean scale\nlibrary(ggplot2)\nxgrid &lt;- data.frame(x1 = seq(-3, 3, length.out = 200), x2 = 0, E = 1)\npred  &lt;- predict(m_pois, newdata = xgrid, type = \"link\", se.fit = TRUE)\neta_hat &lt;- pred$fit\nse_eta  &lt;- pred$se.fit\nmu_hat  &lt;- exp(eta_hat)\nlo      &lt;- exp(eta_hat - 1.96*se_eta)\nhi      &lt;- exp(eta_hat + 1.96*se_eta)\n\nggplot() +\n  geom_point(aes(x = x1, y = y/E), data = dfp, alpha = 0.25) +\n  geom_line(aes(x = xgrid$x1, y = mu_hat), linewidth = 1) +\n  geom_ribbon(aes(x = xgrid$x1, ymin = lo, ymax = hi), alpha = 0.2) +\n  labs(title = \"Poisson GLM (log): effect of x1 | x2=0, E=1\",\n       x = \"x1\", y = \"Rate (λ)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Quick residual check + overdispersion diagnostic\nplot(fitted(m_pois), residuals(m_pois, type = \"deviance\"),\n     xlab = \"Fitted mean λ\", ylab = \"Deviance residual\",\n     main = \"Poisson GLM: residuals vs fitted\")\nabline(h = 0, lty = 2)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#ordinal-regression-proportional-odds",
    "href": "03-4-models.html#ordinal-regression-proportional-odds",
    "title": "4  4 Models",
    "section": "4.6 Ordinal Regression (Proportional Odds)",
    "text": "4.6 Ordinal Regression (Proportional Odds)\nWe observe a response $ Y $ ordinal, or a finely discretized/continuous outcome) and predictors $ x ^p$ .\nWe want to model the conditional cumulative distribution function (CDF)\n\\[\nF(y \\mid x) = P(Y \\le y \\mid x).\n\\]\nFollowing Liu et al. (2017), we use a cumulative probability model (CPM), which is the same mathematical structure as an ordinal / proportional odds regression. \\[\ng\\big( P(Y \\le y \\mid x) \\big)\n= \\alpha(y) - x^\\top \\beta,\n\\tag{1}\n\\] where\n\\[ g(\\cdot) \\] is a link function (logit, probit, loglog, cloglog), \\[ \\alpha(y) \\] is a nondecreasing function of the cutpoint \\[ y \\] (it plays the role of ordered thresholds), \\[ \\beta \\] is a single vector of regression coefficients shared across all cutpoints (this is the proportional / parallel slopes assumption).\nThis is the form used in Liu et al. (2017), Modeling continuous response variables using ordinal regression.\nSuppose \\[Y \\in \\{1,2,\\dots,K\\}.\\]\nDefine \\[\\theta_k = \\alpha(k)\\] for \\[k=1,\\dots,K-1.\\]\nThen (1) becomes the standard cumulative link / proportional odds model\n\\[\ng\\big( P(Y \\le k \\mid x) \\big)\n= \\theta_k - x^\\top \\beta, \\quad k = 1, \\dots, K-1.\n\\]\n\n4.6.1 Choice of link\n\nlogit:\n\\[\ng(p) = \\log\\frac{p}{1-p}, \\qquad\ng^{-1}(y) = \\frac{e^{y}}{1+e^{y}}\n\\]\nprobit:\n\\[\ng(p) = \\Phi^{-1}(p), \\qquad\ng^{-1}(y) = \\Phi(y)\n\\]\nloglog:\n\\[\ng(p) = -\\log\\big(-\\log(p)\\big), \\qquad\ng^{-1}(y) = \\exp\\big[-\\exp(-y)\\big]\n\\]\ncloglog:\n\\[\ng(p) = \\log\\big[-\\log(1-p)\\big], \\qquad\ng^{-1}(y) = 1 - \\exp\\big[-\\exp(y)\\big]\n\\]\n\nHere, \\[\\Phi(\\cdot)\\] is the CDF of the standard normal distribution.\nLet \\[\n\\pi_k(x) = P(Y = k \\mid x), \\quad k=1,\\dots,K.\n\\]\nFrom the cumulative probabilities: \\[\n\\begin{aligned}\nP(Y = 1 \\mid x) &= P(Y \\le 1 \\mid x), \\\\\nP(Y = k \\mid x) &= P(Y \\le k \\mid x) - P(Y \\le k-1 \\mid x), \\quad k=2,\\dots,K-1, \\\\\nP(Y = K \\mid x) &= 1 - P(Y \\le K-1 \\mid x).\n\\end{aligned}\n\\]\nSo with the logit link, the full model is\n\\[\n\\log \\frac{P(Y \\le k \\mid x)}{1 - P(Y \\le k \\mid x)}\n= \\theta_k - x^\\top \\beta, \\quad k=1,\\dots,K-1,\n\\] and the \\[\\pi_k(x)\\] are obtained by the above expressions.\n\n\n4.6.2 Interpretation\n\\(\\beta\\) describes how a one-unit change in a predictor shifts the entire conditional distribution of \\(Y\\). \\(\\theta_k\\) locate the cutpoints between ordered categories. Using different links corresponds to assuming different latent error distributions, as listed in the paper.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#neural-net",
    "href": "03-4-models.html#neural-net",
    "title": "4  4 Models",
    "section": "4.7 Neural Net",
    "text": "4.7 Neural Net\n\n4.7.1 McCulloch–Pitts Neuron (1943)\n\n4.7.1.1 Model Description\nA neuron fires if it receives enough excitatory input and no inhibitory input.\nLet\n- \\(v_i(t) \\in \\{0,1\\}\\)$ activation (firing) state of neuron \\(i\\) at time \\(t\\),\n- \\(E_i\\): set of excitatory inputs,\n- \\(I_i\\): set of inhibitory inputs,\n- \\(T_i\\): excitatory threshold.\n\n\n4.7.1.2 Model Equation\n\\[\nv_i(t+1) =\n\\begin{cases}\n1, & \\text{if } \\displaystyle \\sum_{j \\in E_i} v_j(t) \\ge T_i \\text{ and } \\sum_{k \\in I_i} v_k(t) = 0, \\\\[6pt]\n0, & \\text{otherwise.}\n\\end{cases}\n\\]\nThis is a logical threshold model — the first formal mathematical neuron, but without a learning rule.\n\n\n\n4.7.2 Rosenblatt Perceptron (1958)\n\n4.7.2.1 Model Description\nA single-layer learnable threshold unit for classification.\nLet\n- Input vector \\(x \\in \\mathbb{R}^d\\),\n- Weight vector \\(w \\in \\mathbb{R}^d\\),\n- Bias \\(b\\),\n- Target label \\(t \\in \\{0,1\\}\\).\n\n\n4.7.2.2 Forward Function\n\\[\ny =\n\\begin{cases}\n1, & \\text{if } w^\\top x + b \\ge 0, \\\\[4pt]\n0, & \\text{if } w^\\top x + b &lt; 0.\n\\end{cases}\n\\]\nor equivalently\n\\[\ny = \\mathbf{1}\\{w^\\top x + b \\ge 0\\}.\n\\]\n\n\n4.7.2.3 Learning Rule\nGiven a learning rate (&gt; 0):\n\\[\nw \\leftarrow w + \\eta (t - y) x, \\qquad\nb \\leftarrow b + \\eta (t - y).\n\\]\nIf the perceptron predicts incorrectly, the weights shift toward or away from the input vector to correct the error.\n\n\n\n4.7.3 Rumelhart–Hinton–Williams Backpropagation Network (1986)\nA multilayer feedforward network trained by gradient descent.\nLet\n- Layer index \\(\\ell = 1, 2, \\dots, L\\),\n- Activations \\(a_j^{(\\ell)}\\),\n- Net inputs \\(z_j^{(\\ell)}\\),\n- Weights \\(w_{ij}^{(\\ell)}\\),\n- Biases \\(b_j^{(\\ell)}\\).\n\n4.7.3.1 Forward Pass\nFor the input layer: \\[\na_j^{(1)} = x_j.\n\\]\nFor each hidden or output layer: \\[\nz_j^{(\\ell)} = \\sum_i w_{ij}^{(\\ell)} a_i^{(\\ell-1)} + b_j^{(\\ell)}, \\qquad\na_j^{(\\ell)} = f(z_j^{(\\ell)}),\n\\] where (f) is a differentiable activation function (e.g. sigmoid).\nThe total loss (mean-squared error): \\[\nE = \\frac{1}{2} \\sum_k (t_k - a_k^{(L)})^2.\n\\]\n\n\n4.7.3.2 Backward Pass (Error Terms)\nFor output layer units: \\[\n\\delta_k^{(L)} = (t_k - a_k^{(L)}) f'(z_k^{(L)}).\n\\]\nFor hidden layer units: \\[\n\\delta_j^{(\\ell)} = f'(z_j^{(\\ell)}) \\sum_k w_{jk}^{(\\ell+1)} \\delta_k^{(\\ell+1)}.\n\\]\n\n\n4.7.3.3 Weight and Bias Updates\n\\[\n\\Delta w_{ij}^{(\\ell)} = \\eta \\, a_i^{(\\ell-1)} \\, \\delta_j^{(\\ell)}, \\qquad\nw_{ij}^{(\\ell)} \\leftarrow w_{ij}^{(\\ell)} + \\Delta w_{ij}^{(\\ell)}.\n\\]\n\\[\n\\Delta b_j^{(\\ell)} = \\eta \\, \\delta_j^{(\\ell)}, \\qquad\nb_j^{(\\ell)} \\leftarrow b_j^{(\\ell)} + \\Delta b_j^{(\\ell)}.\n\\]\n\n\n\n4.7.4 Summary Table\n\n\n\n\n\n\n\n\nModel\nOutput Function\nLearning Rule\n\n\n\n\nMcCulloch–Pitts (1943)\n\\[v_i(t+1)=1\\] if enough excitation and no inhibition\nNone (fixed logic)\n\n\nRosenblatt (1958)\n\\[y=\\mathbf{1}\\{w^\\top x + b \\ge 0\\}\\]\n\\[w \\leftarrow w + \\eta (t-y)x\\]\n\n\nRumelhart et al. (1986)\n\\[a_j=f\\!\\left(\\sum_i w_{ij}a_i+b_j\\right)\\]\n\\[\\Delta w_{ij}=\\eta a_i \\delta_j\\] with backpropagation\n\n\n\nThese three equations trace the mathematical evolution of neural networks:\nfrom logical firing (McCulloch–Pitts) → learnable thresholds (Rosenblatt) → differentiable, multilayer learning (Rumelhart–Hinton–Williams).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  },
  {
    "objectID": "03-4-models.html#create-visualizations-of-the-prediction-relationship",
    "href": "03-4-models.html#create-visualizations-of-the-prediction-relationship",
    "title": "4  4 Models",
    "section": "4.8 Create visualizations of the prediction relationship",
    "text": "4.8 Create visualizations of the prediction relationship\n\nlibrary(tidyverse)\nlibrary(nnet)           # for neural net\nlibrary(randomForest)   # for random forest\nlibrary(MASS)           # for polr (ordinal regression)\nset.seed(42)\nn  &lt;- 2000\nX1 &lt;- rnorm(n)\nX2 &lt;- rnorm(n)\nX3 &lt;- rbinom(n, 1, 0.4)\n\nsigmoid &lt;- function(x) 1 / (1 + exp(-x))\nmu &lt;- sqrt(5) * sigmoid(X1 + X3) + sqrt(5) * sigmoid(X2) * X3\nY  &lt;- mu + rnorm(n, 0, 1)\n\ndat &lt;- tibble(X1, X2, X3 = factor(X3), Y)\n\n\nlibrary(tidyverse)\nlibrary(nnet)\nlibrary(randomForest)\nlibrary(MASS)\n\nset.seed(42)\n\n# --- models -------------------------------------------------\nglm_fit &lt;- glm(Y ~ X1 + X2 + X3, data = dat, family = gaussian())\n\ndat &lt;- dat %&gt;%\n  mutate(pred_glm = predict(glm_fit))\n\nnn_fit &lt;- nnet(\n  Y ~ X1 + X2 + X3,\n  data   = dat,\n  size   = 5,\n  linout = TRUE,\n  maxit  = 1000,\n  decay  = 1e-4,\n  trace  = FALSE\n)\n\ndat &lt;- dat %&gt;%\n  mutate(pred_nn = as.numeric(predict(nn_fit, dat)))\n\nrf_fit &lt;- randomForest(\n  Y ~ X1 + X2 + X3,\n  data = dat,\n  ntree = 300,\n  importance = TRUE\n)\n\ndat &lt;- dat %&gt;%\n  mutate(pred_rf = predict(rf_fit, dat))\n\n# --- ordinal target -----------------------------------------\ndat &lt;- dat %&gt;%\n  mutate(\n    Y_ord = cut(\n      Y,\n      breaks = quantile(Y, probs = c(0, 0.33, 0.66, 1)),\n      labels = c(\"Low\", \"Medium\", \"High\"),\n      include.lowest = TRUE,\n      ordered_result = TRUE\n    )\n  )\n\nord_fit &lt;- polr(Y_ord ~ X1 + X2 + X3, data = dat, method = \"logistic\")\n\ndat &lt;- dat %&gt;%\n  mutate(pred_ord = predict(ord_fit, type = \"class\"))\n\n# --- long format for compare plot ---------------------------\ndat_long &lt;- dat %&gt;%\n  dplyr::select(Y, pred_glm, pred_nn, pred_rf) %&gt;%\n  tidyr::pivot_longer(\n    cols = c(pred_glm, pred_nn, pred_rf),\n    names_to = \"model\",\n    values_to = \"prediction\"\n  ) %&gt;%\n  mutate(\n    model = dplyr::recode(\n      model,\n      pred_glm = \"GLM\",\n      pred_nn  = \"Neural Net\",\n      pred_rf  = \"Random Forest\"\n    )\n  )\n\n# --- compare scatter ----------------------------------------\nggplot(dat_long, aes(x = Y, y = prediction)) +\n  geom_point(alpha = 0.25) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  facet_wrap(~ model, nrow = 1) +\n  labs(\n    title = \"Observed vs Predicted: Model Comparison\",\n    x = \"Observed Y\",\n    y = \"Predicted Y\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# --- residual density ---------------------------------------\ndat_long %&gt;%\n  mutate(resid = prediction - Y) %&gt;%\n  ggplot(aes(x = resid, fill = model)) +\n  geom_density(alpha = 0.4) +\n  labs(\n    title = \"Residual distributions by model\",\n    x = \"Prediction error (pred - Y)\",\n    y = \"Density\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4 Models</span>"
    ]
  }
]